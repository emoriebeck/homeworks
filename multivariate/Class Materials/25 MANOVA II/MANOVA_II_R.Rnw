\documentclass[fleqn]{article}
\setlength\parindent{0pt}
\usepackage{fullpage}
\usepackage{dcolumn}
\usepackage{fixltx2e}
\usepackage{amsmath}
\usepackage{scrextend}
\usepackage[sc]{mathpazo}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.5cm,lmargin=2.5cm,rmargin=2.5cm}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}
\usepackage{url}
\usepackage[unicode=true,pdfusetitle,
            bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=2,
            breaklinks=false,pdfborder={0 0 1},backref=false,colorlinks=false]
{hyperref}
\hypersetup{
  pdfstartview={XYZ null null 1}}
\usepackage{breakurl}
\usepackage{amsfonts}
\usepackage[dvips]{epsfig}
\usepackage{algorithm2e}
\usepackage{verbatim}
\usepackage{mathtools}
\usepackage{dcolumn}

<<setup, include=FALSE, cache=FALSE>>=
options(replace.assign=TRUE,width=65, digits=4,scipen=4,fig.width=4,fig.height=4)
library(knitr)
@

\begin{document}
\title{MANOVA\\Part II \\ Psych 516}
\author{Mike Strube}
\date{\today}
\maketitle

\section{Preliminaries}
\textbf{\large{\textit{
The RStudio workspace and console panes are cleared of old output, variables, and other miscellaneous debris. 
Then some packages are loaded and the required data files are input.
}}}
\subsection{Clear the Console Panes and Load Packages}
<<tidy=TRUE>>=
options(replace.assign=TRUE,width=65, digits=4,scipen=4,fig.width=4,fig.height=4)
# Clear the workspace and console.
rm(list = ls(all = TRUE)) 
cat("\014")
# Turn off showing of significance asterisks.
options(show.signif.stars=F)
# Set the contrast option; important for ANOVAs.
options(contrasts = c('contr.sum','contr.poly'))
how_long <- Sys.time()
set.seed(123)
library(knitr)
@

<<tidy=TRUE>>=
library(psych)
library(ggplot2)
library(MASS)
library(sciplot)
library(dplyr)
library(aod)
library(MVN)
library(boot)
library(car)
library(LogisticDx)
library(biotools)
library(multcomp)
library(candisc)
library(ez)
library(GGally)
library(qqplotr)
library(gridExtra)
library(reshape)
library(emmeans)
@

\subsection{Data}
<<tidy=TRUE>>=
setwd("C:\\Courses\\Psychology 516\\PowerPoint\\2018")

Skills <- read.table('manova.csv',sep=',',header=TRUE)
Skills <- as.data.frame(Skills)
@

\subsection{Data Modifications}
\textbf{\large{\textit{
Residualized versions of continuous predictors are created so that preliminary analyses are not contaminated by outcome differences.
Labeled variables are created to assist in creation of some tables and graphs.
Dummy codes and linear combinations are created for specialized analyses (not all used here).
}}}
<<tidy=TRUE>>=
# Residuals
Skills$P_Verbal_R <- lm(P_Verbal ~ as.factor(Group), data=Skills)$residuals
Skills$P_Quant_R <- lm(P_Quant ~ as.factor(Group), data=Skills)$residuals
Skills$C_Verbal_R <- lm(C_Verbal ~ as.factor(Group), data=Skills)$residuals
Skills$C_Quant_R <- lm(C_Quant ~ as.factor(Group), data=Skills)$residuals

# Labels
Skills$Tx_P2[Skills$Tx_P=="1"] <- "No Paper Tx"
Skills$Tx_P2[Skills$Tx_P=="2"] <- "Paper Tx"

Skills$Tx_C2[Skills$Tx_C=="1"] <- "No Computer Tx"
Skills$Tx_C2[Skills$Tx_C=="2"] <- "Computer Tx"

Skills$Group2[Skills$Group=="1"] <- "No Paper Tx and No Computer Tx"
Skills$Group2[Skills$Group=="2"] <- "Paper Tx and No Computer Tx"
Skills$Group2[Skills$Group=="3"] <- "No Paper Tx and Computer Tx"
Skills$Group2[Skills$Group=="4"] <- "Paper Tx and Computer Tx"

Skills$Group3[Skills$Group=="1"] <- "No P, No C"
Skills$Group3[Skills$Group=="2"] <- "P, No C"
Skills$Group3[Skills$Group=="3"] <- "No P, C"
Skills$Group3[Skills$Group=="4"] <- "P, C"

# Dummy variables to be used in between-groups analyses.
Skills$D1[Skills$Group==1] <- 1
Skills$D2[Skills$Group==1] <- 0
Skills$D3[Skills$Group==1] <- 0
Skills$D4[Skills$Group==1] <- 0
Skills$D1[Skills$Group==2] <- 0
Skills$D2[Skills$Group==2] <- 1
Skills$D3[Skills$Group==2] <- 0
Skills$D4[Skills$Group==2] <- 0
Skills$D1[Skills$Group==3] <- 0
Skills$D2[Skills$Group==3] <- 0
Skills$D3[Skills$Group==3] <- 1
Skills$D4[Skills$Group==3] <- 0
Skills$D1[Skills$Group==4] <- 0
Skills$D2[Skills$Group==4] <- 0
Skills$D3[Skills$Group==4] <- 0
Skills$D4[Skills$Group==4] <- 1

# Add contrast codes to reflect main effects and interactions.
Skills$C1[Skills$Group==1] <- -1
Skills$C2[Skills$Group==1] <- -1
Skills$C3[Skills$Group==1] <- 1
Skills$C1[Skills$Group==2] <- 1
Skills$C2[Skills$Group==2] <- -1
Skills$C3[Skills$Group==2] <- -1
Skills$C1[Skills$Group==3] <- -1
Skills$C2[Skills$Group==3] <- 1
Skills$C3[Skills$Group==3] <- -1
Skills$C1[Skills$Group==4] <- 1
Skills$C2[Skills$Group==4] <- 1
Skills$C3[Skills$Group==4] <- 1

# Add contrast codes to reflect specialized comparisons.
Skills$S1[Skills$Group==1] <- 3
Skills$S2[Skills$Group==1] <- 0
Skills$S3[Skills$Group==1] <- 0
Skills$S1[Skills$Group==2] <- -1
Skills$S2[Skills$Group==2] <- 2
Skills$S3[Skills$Group==2] <- 0
Skills$S1[Skills$Group==3] <- -1
Skills$S2[Skills$Group==3] <- -1
Skills$S3[Skills$Group==3] <- 1
Skills$S1[Skills$Group==4] <- -1
Skills$S2[Skills$Group==4] <- -1
Skills$S3[Skills$Group==4] <- -1

# Outcome linear combinations to be used in repeated measures analyses.
Skills$Sum <- Skills$P_Verbal+Skills$P_Quant+Skills$C_Verbal+Skills$C_Quant
Skills$Domain <- Skills$P_Verbal-Skills$P_Quant+Skills$C_Verbal-Skills$C_Quant
Skills$Mode <- Skills$P_Verbal+Skills$P_Quant-Skills$C_Verbal-Skills$C_Quant
Skills$DxM <- Skills$P_Verbal-Skills$P_Quant-Skills$C_Verbal+Skills$C_Quant

# Create a non-factor version of the condition variables
# before converting them to factors.
Skills$Tx_P_NF <- Skills$Tx_P
Skills$Tx_C_NF <- Skills$Tx_C

# Convert to factors
Skills$Tx_P = factor(Skills$Tx_P, levels=c(1,2), labels=c("No Tx(P)","Tx(P)"))
Skills$Tx_C = factor(Skills$Tx_C, levels=c(1,2), labels=c("No Tx(C)","Tx(C)"))

# Sort file by Group
Skills <- Skills[order(Skills$Group),] 
@

\clearpage
\section{Data Characteristics}
\textbf{\large{\textit{
These hypothetical data simulate a training study in which students are given training to take tests of verbal and quantitative ability.
The training is conducted either with paper-and-pencil (standard) tests or with computer-administered tests (or both) and the tests are administered in both formats. 
The basic nature of these data is explored here.
}}}

\subsection{Some Descriptive Statistics}
\textbf{\large{\textit{
Some basic descriptive statistics give an initial glimpse of the data.
}}}
<<tidy=TRUE>>=
describeBy(Skills[,2:5],group=Skills$Group)

with(Skills, tapply(P_Verbal, list(Tx_P,Tx_C), mean))
with(Skills, tapply(P_Quant, list(Tx_P,Tx_C), mean))
with(Skills, tapply(C_Verbal, list(Tx_P,Tx_C), mean))
with(Skills, tapply(C_Quant, list(Tx_P,Tx_C), mean))

with(Skills, tapply(P_Verbal, list(Tx_P,Tx_C), sd))
with(Skills, tapply(P_Quant, list(Tx_P,Tx_C), sd))
with(Skills, tapply(C_Verbal, list(Tx_P,Tx_C), sd))
with(Skills, tapply(C_Quant, list(Tx_P,Tx_C), sd))
@

\subsection{Basic Visualization}
\textbf{\large{\textit{
The basic nature of the data is easily viewed with some simple graphics.
}}}

<<tidy=TRUE>>=
ggpairs(Skills[9:12],
      lower = list(continuous = "smooth"),
      upper = list(continuous = "cor"),
      columnLabels=c("Paper:\n Verbal","Paper:\n Quantitative","Computer:\n Verbal","Computer:\n Quantitative")) +
      theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=9,face="bold"),
          axis.text.x = element_text(colour = "black",size=9,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
  ggtitle("Correlations Among Outcome Measures (Residuals)")
@

<<tidy=TRUE>>=
Skills$Group4 <- factor(Skills$Group3,levels=c("No P, No C","No P, C","P, No C","P, C"),
                        labels=c("No P, No C","No P, C","P, No C","P, C"))

p1 <- ggplot(Skills, aes(x=as.factor(Group4), y=P_Verbal)) + 
        geom_boxplot(fill="gray") +
        ylab("Outcome") +
        xlab("Training Group") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=14), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=14),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
        ggtitle("Paper: Verbal")

p2 <- ggplot(Skills, aes(x=as.factor(Group4), y=P_Quant)) + 
        geom_boxplot(fill="gray") +
        ylab("Outcome") +
        xlab("Training Group") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=14), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=14),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
        ggtitle("Paper: Quantitative")

p3 <- ggplot(Skills, aes(x=as.factor(Group4), y=C_Verbal)) + 
        geom_boxplot(fill="gray") +
        ylab("Outcome") +
        xlab("Training Group") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=14), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=14),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
        ggtitle("Computer: Verbal")

p4 <- ggplot(Skills, aes(x=as.factor(Group4), y=C_Quant)) + 
        geom_boxplot(fill="gray") +
        ylab("Outcome") +
        xlab("Training Group") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=14), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=14),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
        ggtitle("Computer: Quantitative")
grid.arrange(p1,p2,p3,p4,nrow=2)
@

\section{Multivariate Normality Assumption}
\textbf{\large{\textit{
The classification part of discriminant analysis (as well as any significance tests for the discriminant functions) rely on the multivariate normality assumption.
Because MANOVA is inherently a discriminant analysis, we make the same assumption.
The tests are performed on the residualized data so that group differences do not affect the results.
Note that a violation of multivariate normality will also affect the test of homogeneity of covariance matrices.
}}}

\subsection{Full Sample}
<<tidy=TRUE>>=
mvn(Skills[,9:12],mvnTest="mardia")
@

<<tidy=TRUE>>=
CV <- cov(Skills[,9:12])
D2_1 <- mahalanobis(Skills[,9:12],center=colMeans(Skills[,9:12]),cov=CV)
D2_1 <- as.data.frame(D2_1)
ggplot(D2_1, aes(sample=D2_1)) +
    stat_qq_band(distribution = "chisq", dparams = list(df=4)) +
    stat_qq_line(distribution = "chisq", dparams = list(df=4)) + 
    stat_qq(distribution = "qchisq", dparams = list(df=4)) +
    scale_y_continuous(breaks=seq(0,24,2)) +
    scale_x_continuous(breaks=seq(0,16,1)) +
    coord_cartesian(xlim = c(0,16), ylim =c(0,24)) +
    xlab(expression("Expected Values from" * ~ chi[4]^2)) + 
    ylab(expression("Mahalanobis " * ~D^2)) +
    theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
  ggtitle(expression("Q-Q Plot of Mahalanobis" * ~D^2 *
                         " vs. Quantiles of" * ~ chi[4]^2))
@

\subsection{Outlier Excluded}
<<tidy=TRUE>>=
Skills$D2_1 <- D2_1
Skills_Trimmed <- Skills[which(Skills$D2_1!=max(Skills$D2_1)),]

mvn(Skills_Trimmed[,9:12],mvnTest="mardia")
@

<<tidy=TRUE>>=
CV <- cov(Skills_Trimmed[,9:12])
D2_1 <- mahalanobis(Skills_Trimmed[,9:12],center=colMeans(Skills_Trimmed[,9:12]),cov=CV)
D2_1 <- as.data.frame(D2_1)
ggplot(D2_1, aes(sample=D2_1)) +
    stat_qq_band(distribution = "chisq", dparams = list(df=4)) +
    stat_qq_line(distribution = "chisq", dparams = list(df=4)) + 
    stat_qq(distribution = "qchisq", dparams = list(df=4)) +
    scale_y_continuous(breaks=seq(0,24,2)) +
    scale_x_continuous(breaks=seq(0,16,1)) +
    coord_cartesian(xlim = c(0,16), ylim =c(0,24)) +
    xlab(expression("Expected Values from" * ~ chi[4]^2)) + 
    ylab(expression("Mahalanobis " * ~D^2)) +
    theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
          axis.text.y = element_text(colour = "black",size=12,face="bold"),
          axis.text.x = element_text(colour = "black",size=12,face="bold",angle=90),
          axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
          axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
          axis.line.x = element_blank(),
          axis.line.y = element_blank(),
          plot.title = element_text(size=16, face="bold", 
                                    margin = margin(0, 0, 20, 0),hjust=.5),
          panel.background = element_rect(fill = "white",linetype = 1,color="black"),
          panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),  
          plot.background = element_rect(fill = "white"),
          plot.margin = unit(c(1, 1, 1, 1), "cm"),
          legend.position = "bottom", 
          legend.title = element_blank()) +
  ggtitle(expression("Q-Q Plot of Mahalanobis" * ~D^2 *
                         " vs. Quantiles of" * ~ chi[4]^2))
@

<<tidy=TRUE>>=
Skills_Trimmed_QQ <- scale(Skills_Trimmed[,9:12])
Data_long <- melt(Skills_Trimmed_QQ)
Data_long <- as.data.frame(Data_long)
names(Data_long) <- c("Index","feature","value")
Data_long$feature_F <- factor(Data_long$feature,levels=c("P_Verbal_R","P_Quant_R","C_Verbal_R","C_Quant_R"),
                         labels = c("Paper: Verbal","Paper: Quantitative","Computer: Verbal","Computer: Quantitative"))
p <- ggplot(Data_long, aes(sample=value)) +
        stat_qq_band() + stat_qq_line() + stat_qq(distribution=qnorm,size=1) +
        scale_y_continuous(breaks=seq(-4,4,1)) +
        scale_x_continuous(breaks=seq(-4,4,1)) +
        coord_cartesian(xlim = c(-4,4), ylim =c(-4,4)) +
        xlab("Theoretical Quantiles") + 
        ylab("Sample Quantiles") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=10,face="bold"),
              axis.text.x = element_text(colour = "black",size=10,face="bold",angle=90),
              axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=16, face="bold", 
                                        margin = margin(0, 0, 20, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),  
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
      ggtitle("Q-Q Plots for Job Search Features")
p + facet_wrap(~feature_F)
@

\clearpage
\section{Homogeneity Assumption}
\textbf{\large{\textit{
We assume in discriminant analysis that the separate group variance-covariance matrices are homogeneous.
Box's test can be used to test this assumption.
Note, however, that it is also sensitive to violations of multivariate normality.
}}}
<<tidy=TRUE>>=
boxM(Skills[,2:5], Skills$Group)
boxM(Skills[,2:5], Skills$Group)$cov
boxM(Skills[,2:5], Skills$Group)$pooled

boxM(Skills_Trimmed[,2:5], Skills_Trimmed$Group)
boxM(Skills_Trimmed[,2:5], Skills_Trimmed$Group)$cov
boxM(Skills_Trimmed[,2:5], Skills_Trimmed$Group)$pooled
@

\clearpage
\section{Means and Confidence Intervals}
\textbf{\large{\textit{
Displayed here are bar graphs of the condition means with 95\% confidence intervals.
}}}

<<tidy=TRUE>>=
D <- describeBy(Skills_Trimmed[,2:5],group=Skills_Trimmed$Group4)

plot_data <- matrix(NA,nrow=4,ncol=8)

for(i in 1:4) {
  for(j in 1:4) {
    plot_data[i,j] <- D[[i]]$mean[j]
    plot_data[i,j+4] <- qt(.975,D[[i]]$n[j])*D[[i]]$sd[j]/sqrt(D[[i]]$n[j])
  }
}
plot_data <- as.data.frame(plot_data)
names(plot_data) <- c("PV_mean","PQ_mean","CV_mean","CQ_mean","PV_CI","PQ_CI","CV_CI","CQ_CI")
plot_data$Group3 <- factor(c("No P, No C","No P, C","P, No C","P, C"))
plot_data$Group4 <- factor(plot_data$Group3,levels=c("No P, No C","No P, C","P, No C","P, C"),
                        labels=c("No P, No C","No P, C","P, No C","P, C"))
@

<<tidy=TRUE>>=
p1 <- ggplot(plot_data, aes(x=as.factor(Group4), y=PV_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=PV_mean-PV_CI, ymax=PV_mean+PV_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,10))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=12,face="bold"),
              axis.text.x = element_text(colour = "black",size=12,face="bold",angle=0,hjust=1),
              axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=16, face="bold", 
                                        margin = margin(0, 0, 20, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Mean Paper-Verbal by\n Treatment Group (95% CI)")
print(p1)
@

<<tidy=TRUE>>=
p2 <- ggplot(plot_data, aes(x=as.factor(Group4), y=PQ_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=PQ_mean-PQ_CI, ymax=PQ_mean+PQ_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,10))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=12,face="bold"),
              axis.text.x = element_text(colour = "black",size=12,face="bold",angle=0,hjust=1),
              axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=16, face="bold", 
                                        margin = margin(0, 0, 20, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Mean Paper-Quantitative by\n Treatment Group (95% CI)")
print(p2)
@

<<tidy=TRUE>>=
p3 <- ggplot(plot_data, aes(x=as.factor(Group4), y=CV_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=CV_mean-CV_CI, ymax=CV_mean+CV_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,10))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=12,face="bold"),
              axis.text.x = element_text(colour = "black",size=12,face="bold",angle=0,hjust=1),
              axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=16, face="bold", 
                                        margin = margin(0, 0, 20, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Mean Computer-Verbal by\n Treatment Group (95% CI)")
print(p3)
@

<<tidy=TRUE>>=
p4 <- ggplot(plot_data, aes(x=as.factor(Group4), y=CQ_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=CQ_mean-CQ_CI, ymax=CQ_mean+CQ_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,10))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=12,face="bold"),
              axis.text.x = element_text(colour = "black",size=12,face="bold",angle=0,hjust=1),
              axis.title.x = element_text(margin=margin(15,0,0,0),size=16), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=16),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=16, face="bold", 
                                        margin = margin(0, 0, 20, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Mean Computer-Quantitative by\n Treatment Group (95% CI)")
print(p4)
@

<<tidy=TRUE>>=
p1 <- ggplot(plot_data, aes(x=as.factor(Group4), y=PV_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=PV_mean-PV_CI, ymax=PV_mean+PV_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,20))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=10,face="bold"),
              axis.text.x = element_text(colour = "black",size=10,face="bold",angle=45,hjust=1),
              axis.title.x = element_text(margin=margin(5,0,0,0),size=12), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=12),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=14, face="bold", 
                                        margin = margin(0, 0, 5, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Paper \n Verbal (95% CI)")
@

<<tidy=TRUE>>=
p2 <- ggplot(plot_data, aes(x=as.factor(Group4), y=PQ_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=PQ_mean-PQ_CI, ymax=PQ_mean+PQ_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,20))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=10,face="bold"),
              axis.text.x = element_text(colour = "black",size=10,face="bold",angle=45,hjust=1),
              axis.title.x = element_text(margin=margin(5,0,0,0),size=12), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=12),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=14, face="bold", 
                                        margin = margin(0, 0, 5, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Paper \n Quantitative (95% CI)")
@

<<tidy=TRUE>>=
p3 <- ggplot(plot_data, aes(x=as.factor(Group4), y=CV_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=CV_mean-CV_CI, ymax=CV_mean+CV_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,20))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=10,face="bold"),
              axis.text.x = element_text(colour = "black",size=10,face="bold",angle=45,hjust=1),
              axis.title.x = element_text(margin=margin(5,0,0,0),size=12), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=12),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=14, face="bold", 
                                        margin = margin(0, 0, 5, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Computer \n Verbal (95% CI)")
@

<<tidy=TRUE>>=
p4 <- ggplot(plot_data, aes(x=as.factor(Group4), y=CQ_mean)) + 
        geom_bar(position=position_dodge(), stat="identity",color="black",width=.5,fill="grey") +
        geom_errorbar(aes(ymin=CQ_mean-CQ_CI, ymax=CQ_mean+CQ_CI),
                      width=.1,position = position_dodge(0.5)) +
        scale_y_continuous(breaks=c(seq(0,100,20))) +  
        coord_cartesian(ylim = c(0,100)) +
        xlab("Treatment Group") + 
        ylab("Outcome") +
        theme(text=element_text(size = 14, family = "sans", color = "black", face="bold"),
              axis.text.y = element_text(colour = "black",size=10,face="bold"),
              axis.text.x = element_text(colour = "black",size=10,face="bold",angle=45,hjust=1),
              axis.title.x = element_text(margin=margin(5,0,0,0),size=12), 
              axis.title.y = element_text(margin=margin(0,15,0,0),size=12),
              axis.line.x = element_blank(),
              axis.line.y = element_blank(),
              plot.title = element_text(size=14, face="bold", 
                                        margin = margin(0, 0, 5, 0),hjust=.5),
              panel.background = element_rect(fill = "white",linetype = 1,color="black"),
              panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.border = element_rect(fill = NA, size=.5),
              plot.background = element_rect(fill = "white"),
              plot.margin = unit(c(1, 1, 1, 1), "cm"),
              legend.position = "bottom", 
              legend.title = element_blank()) +
        ggtitle("Computer \n Quantitative (95% CI)")
grid.arrange(p1,p2,p3,p4,nrow=2)
@

\clearpage
\section{Within-Groups Correlations}
\textbf{\large{\textit{
Coorelations among the residuals indicate the amount of redundancy among the variables.
}}}

<<tidy=TRUE>>=
cor(Skills_Trimmed[,9:12])
@

\clearpage
\section{ANOVA of Each Outcome \\ No Group Structure}
\textbf{\large{\textit{
Simple one-way ANOVAs can determine if each measure can distinguish the groups.
}}}
<<tidy=TRUE>>=
AOV_1 <- aov(P_Verbal ~ as.factor(Group),data=Skills_Trimmed)
summary(AOV_1)
TukeyHSD(AOV_1)

AOV_2 <- aov(P_Quant ~ as.factor(Group),data=Skills_Trimmed)
summary(AOV_2)
TukeyHSD(AOV_2)

AOV_3 <- aov(C_Verbal ~ as.factor(Group),data=Skills_Trimmed)
summary(AOV_3)
TukeyHSD(AOV_3)

AOV_4 <- aov(C_Quant ~ as.factor(Group),data=Skills_Trimmed)
summary(AOV_4)
TukeyHSD(AOV_4)
@

\clearpage
\section{Discriminant Analysis}
\textbf{\large{\textit{
A discriminant analysis with no imposed structure on the groups.
This is the most exploratory approach that we can take with these data, aimed at discovering how the groups can best be separated with weighted linear combinations of the measures.
}}}

\subsection{No Group Structure}
\textbf{\large{\textit{
The candisc( ) function provides a flexible way to conduct the discriminant analysis.
It provides the most important information (coefficients, significance tests, etc.), including
the ability to plot the group locations (and individual data points) on the discriminant functions.
}}}

<<tidy=TRUE>>=
# This function takes as input the data frame used 
# for a discriminant analysis along with the
# object into which the discriminant analysis results
# are saved. The candisc( ) function is assumed to
# be used for the discriminant analysis. The function
# return a chi-square test of the hypothesis that the
# current discriminant function and all subsequent
# discriminant functions provide no significant
# group separation. The test parallels the F ratio
# version reported by candisc( ) function.
DA_Chi_Square <- function(data_frame,candisc_object) {
  n <- length(data_frame[,1])
  q <- length(candisc_object$coeffs.std[,1])
  g <- length(unique(candisc_object$factors)[,1])
  W <- Wilks(candisc_object)
  for(i in seq(1,candisc_object$ndim,1)) {
    k <- i-1
    chi_test <- -(n-(q+g)/2-1)*log(W$`LR test stat`[i])
    chi_df <- (q-k)*(g-k-1)
    chi_p <-   pchisq(chi_test,chi_df,lower.tail=FALSE)
    if(i==1) {
      results <- c(chi_test,chi_df,chi_p)
    } else {
      results <- rbind(results, c(chi_test,chi_df,chi_p))
    }    
  }
  colnames(results) <- c("Chi_Sq","df","p")
  return(results)
}
@

<<tidy=TRUE>>=
LM_1 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ as.factor(Group),data=Skills_Trimmed)
LDA_1 <- candisc(LM_1, data=Skills_Trimmed)
LDA_1
summary(LDA_1)
LDA_1$dfh
LDA_1$dfe
LDA_1$pct
LDA_1$ndim
LDA_1$coeffs.raw
LDA_1$coeffs.std
LDA_1$structure

DA_Chi_Square(Skills_Trimmed,LDA_1)

plot(LDA_1,main=list("Group Locations on Discriminant Functions",cex=1.5),cex=1.25,font.axis=2,
     col=c("red","blue","green","black"),pch=c(16,16,16,16),font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2,which=c(1,2))
abline(v=0,lty=2,lwd=2,col="black")
abline(h=0,lty=2,lwd=2,col="black")
legend("bottomright",c("No P, No C","P, No C","No P, C","P, C"),col=c("red","blue","green","black"),pch=16)

plot(LDA_1,main=list("Group Locations on Discriminant Functions",cex=1.5),cex=1.25,font.axis=2,
     col=c("red","blue","green","black"),pch=c(16,16,16,16),font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2,which=c(1,3))
abline(v=0,lty=2,lwd=2,col="black")
abline(h=0,lty=2,lwd=2,col="black")
legend("bottomright",c("No P, No C","P, No C","No P, C","P, C"),col=c("red","blue","green","black"),pch=16)

plot(LDA_1,main=list("Group Locations on Discriminant Functions",cex=1.5),cex=1.25,font.axis=2,
     col=c("red","blue","green","black"),pch=c(16,16,16,16),font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2,which=c(2,3))
abline(v=0,lty=2,lwd=2,col="black")
abline(h=0,lty=2,lwd=2,col="black")
legend("bottomright",c("No P, No C","P, No C","No P, C","P, C"),col=c("red","blue","green","black"),pch=16)
@

\textbf{\large{\textit{
The manova( ) function is also useful.
It provides the full set of significance tests as well as the sums of squares and cross-products matrices on which the tests are based.
}}}
<<tidy=TRUE>>=
Outcomes <- as.matrix(Skills_Trimmed[,2:5])
MANOVA_1 <- manova(Outcomes~as.factor(Group),data=Skills_Trimmed)
summary(MANOVA_1,test="Wilks")
summary(MANOVA_1,test="Hotelling")
summary(MANOVA_1,test="Pillai")
summary(MANOVA_1,test="Roy")
summary(MANOVA_1)$SS
summary(MANOVA_1)$stats
summary(MANOVA_1)$Eigenvalues
summary.aov(MANOVA_1)
@

\textbf{\large{\textit{
The Manova( ) function (note capitalization) allows specifying Type II or Type III sums of squares.
That is not useful here with group unstructured, but could be important in unbalanced designs.
This function also provides the sums of squares and cross-products matrices.
}}}
<<tidy=TRUE>>=
LM_4 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ as.factor(Group), data=Skills_Trimmed)
MANOVA_3 <- Manova(LM_4,type="III")
summary(MANOVA_3,multivariate=TRUE)
MANOVA_3 <- Manova(LM_4,type="II")
summary(MANOVA_3,multivariate=TRUE)
@

\subsection{Group Structure}
\textbf{\large{\textit{
The discriminant analysis can also be performed on "groups" defined by contrasts.
These might represent a factorial structure or other comparisons of interest.
}}}
\subsubsection{Factorial Structure}
<<tidy=TRUE>>=
LM_2 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ Tx_P + Tx_C + Tx_P:Tx_C,data=Skills_Trimmed)
LDA_2 <- candisc(LM_2, term="Tx_P",data=Skills_Trimmed,type="2")
LDA_2
summary(LDA_2)
LDA_2$dfh
LDA_2$dfe
LDA_2$pct
LDA_2$ndim
LDA_2$coeffs.raw
LDA_2$coeffs.std
LDA_2$structure
plot(LDA_2,cex=1.25,font.axis=2, 
     font.lab=2,cex.lab=1.5, 
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_3 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ Tx_P + Tx_C + Tx_P:Tx_C,data=Skills_Trimmed)
LDA_3 <- candisc(LM_3, term="Tx_C",data=Skills_Trimmed,type="2")
LDA_3
summary(LDA_3)
LDA_3$dfh
LDA_3$dfe
LDA_3$pct
LDA_3$ndim
LDA_3$coeffs.raw
LDA_3$coeffs.std
LDA_3$structure
plot(LDA_3,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_4 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ Tx_P + Tx_C + Tx_P:Tx_C,data=Skills_Trimmed)
LDA_4 <- candisc(LM_4, term="Tx_P:Tx_C",data=Skills_Trimmed,type="2")
LDA_4
summary(LDA_4)
LDA_4$dfh
LDA_4$dfe
LDA_4$pct
LDA_4$ndim
LDA_4$coeffs.raw
LDA_4$coeffs.std
LDA_4$structure
plot(LDA_4,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

\subsubsection{Factorial Structure by Contrast Codes}
<<tidy=TRUE>>=
LM_5 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ C1 + C2 + C3,data=Skills_Trimmed)
LDA_5 <- candisc(LM_5, term="C3", data=Skills_Trimmed,type="2")
LDA_5
summary(LDA_5)
LDA_5$dfh
LDA_5$dfe
LDA_5$pct
LDA_5$ndim
LDA_5$coeffs.raw
LDA_5$coeffs.std
LDA_5$structure
plot(LDA_5,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_6 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ C1 + C2,data=Skills_Trimmed)
LDA_6 <- candisc(LM_6, term="C2", data=Skills_Trimmed,type="2")
LDA_6
summary(LDA_6)
LDA_6$dfh
LDA_6$dfe
LDA_6$pct
LDA_6$ndim
LDA_6$coeffs.raw
LDA_6$coeffs.std
LDA_6$structure
plot(LDA_6,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

\subsubsection{Special Contrast Codes}
<<tidy=TRUE>>=
LM_7 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ S1 + S2 + S3,data=Skills_Trimmed)
LDA_7 <- candisc(LM_7, term="S1", data=Skills_Trimmed,type="2")
LDA_7
summary(LDA_7)
LDA_7$dfh
LDA_7$dfe
LDA_7$pct
LDA_7$ndim
LDA_7$coeffs.raw
LDA_7$coeffs.std
LDA_7$structure
plot(LDA_7,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_8 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ S1 + S2 + S3,data=Skills_Trimmed)
LDA_8 <- candisc(LM_8, term="S2", data=Skills_Trimmed,type="2")
LDA_8
summary(LDA_8)
LDA_8$dfh
LDA_8$dfe
LDA_8$pct
LDA_8$ndim
LDA_8$coeffs.raw
LDA_8$coeffs.std
LDA_8$structure
plot(LDA_8,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_9 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ S1 + S2 + S3,data=Skills_Trimmed)
LDA_9 <- candisc(LM_9, term="S3", data=Skills_Trimmed,type="2")
LDA_9
summary(LDA_9)
LDA_9$dfh
LDA_9$dfe
LDA_9$pct
LDA_9$ndim
LDA_9$coeffs.raw
LDA_9$coeffs.std
LDA_9$structure
plot(LDA_9,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

\subsubsection{Dummy Codes}
<<tidy=TRUE>>=
LM_10 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ D1 + D2 + D3,data=Skills_Trimmed)
LDA_10 <- candisc(LM_10, term="D3", data=Skills_Trimmed,type="2")
LDA_10
summary(LDA_10)
LDA_10$dfh
LDA_10$dfe
LDA_10$pct
LDA_10$ndim
LDA_10$coeffs.raw
LDA_10$coeffs.std
LDA_10$structure
plot(LDA_10,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

<<tidy=TRUE>>=
LM_11 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant) ~ D1 + D2 + D3,data=Skills_Trimmed)
LDA_11 <- candisc(LM_11, term="D1", data=Skills_Trimmed,type="2")
LDA_11
summary(LDA_11)
LDA_11$dfh
LDA_11$dfe
LDA_11$pct
LDA_11$ndim
LDA_11$coeffs.raw
LDA_11$coeffs.std
LDA_11$structure
plot(LDA_11,cex=1.25,font.axis=2,
     font.lab=2,cex.lab=1.5,
     prefix="Discriminant Function ",var.col="black",var.lwd=2)
@

\section{Univariate Repeated Measures with Sphericity Test}
\textbf{\large{\textit{
This method, however, does produce the univariate repeated measures F tests.
They are based on separate error terms for each within-subjects effect.
Note that a test of sphericity is not given because all within-subjects effects are 1 degree of freedom.
}}}
<<tidy=TRUE>>=
Mode <- factor(rep(c("Paper","Computer"),c(2,2)),levels=c("Paper","Computer"))
Domain <- factor(rep(c("Verbal","Quant"),2),levels=c("Verbal","Quant"))
idata <- data.frame(Mode,Domain)

LM_6 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant)~Tx_P*Tx_C,data=Skills_Trimmed)
LM_6
ANOVA_1 <- Anova(LM_6,idata=idata,idesign=~Mode*Domain,type=2)
ANOVA_2 <- Anova(LM_6,idata=idata,idesign=~Mode*Domain,type=3)
summary(ANOVA_1,multivariate=FALSE)
summary(ANOVA_2,multivariate=FALSE)
@

\textbf{\large{\textit{
In this version, the factorial structure on the within-subjects side is ignored.
Now the 3 degrees of freedom for the within-subjects effect require the sphericity assumption and that test is provided.
}}}
<<tidy=TRUE>>=
Measure <- factor(c("P_V","P_Q","C_V","C_Q"),levels=c("P_V","P_Q","C_V","C_Q"))
idata <- data.frame(Measure)

LM_7 <- lm(cbind(P_Verbal,P_Quant,C_Verbal,C_Quant)~Tx_P*Tx_C,data=Skills_Trimmed)
LM_7
ANOVA_3 <- Anova(LM_7,idata=idata,idesign=~Measure,type=2)
ANOVA_4 <- Anova(LM_7,idata=idata,idesign=~Measure,type=3)
summary(ANOVA_3,multivariate=FALSE)
summary(ANOVA_4,multivariate=FALSE)
@


\section{Roy-Bargman Step-Down Tests}
\textbf{\large{\textit{
The redundancy question can be addressed using the Roy-Bargman stepdown procedure. 
The dependent variables are tested in a univariate fashion, in a specific order, with earlier-considered dependent variables used as covariates for later dependent variables.
All dependent variables add significantly to group differentiation.
}}}
<<tidy=TRUE>>=
summary(aov(P_Verbal ~ P_Quant + C_Verbal + C_Quant + as.factor(Group), data=Skills_Trimmed))
summary(aov(P_Quant ~  P_Verbal + C_Verbal + C_Quant + as.factor(Group), data=Skills_Trimmed))
summary(aov(C_Verbal ~ P_Quant + P_Verbal + C_Quant + as.factor(Group), data=Skills_Trimmed))
summary(aov(C_Quant ~ P_Quant + C_Verbal +  P_Verbal + as.factor(Group), data=Skills_Trimmed))
@

<<tidy=TRUE>>=
Sys.time()-how_long
@
\end{document}